{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch is a popular deep learning framework and it's easy to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read the mnist data, preprocess them and encapsulate them into dataloader form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "normalize = transforms.Normalize(mean=[.5], std=[.5])\n",
    "transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "\n",
    "# download and load the data\n",
    "train_dataset = torchvision.datasets.MNIST(root='./mnist/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./mnist/', train=False, transform=transform, download=False)\n",
    "\n",
    "# encapsulate them into dataloader form\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the model, object function and optimizer that we use to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "# TODO:define model\n",
    "    def __init__(self):\n",
    "        super(SimpleNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5,padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(16,500,kernel_size=5)\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        self.relu = nn.ReLU()\n",
    "        #self.fc1 = nn.Linear(120,84)\n",
    "        #self.fc2 = nn.Linear(84,10)\n",
    "        self.fc2 = nn.Linear(500,10)\n",
    "        #self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        #S1，2 卷积与池化\n",
    "        out = self.relu(self.mp(self.conv1(x)))\n",
    "        out = self.relu(self.mp(self.conv2(out)))\n",
    "        out = self.relu(self.conv3(out))\n",
    "        out = out.view( in_size,-1 )\n",
    "        #out = self.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return F.log_softmax(out, dim=0)\n",
    "    \n",
    "model = SimpleNet()\n",
    "\n",
    "# TODO:define loss function and optimiter\n",
    "#criterion = F.nll_loss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.02, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can start to train and evaluate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 468/468 [07:36<00:00,  3.95it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 468/468 [00:43<00:00, 10.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuary: 97.00 %\n",
      "Testing Accuracy: 97.00 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 468/468 [01:31<00:00,  3.08it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 468/468 [00:34<00:00, 16.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuary: 98.00 %\n",
      "Testing Accuracy: 98.00 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 468/468 [01:12<00:00,  6.79it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 468/468 [00:36<00:00, 12.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuary: 98.00 %\n",
      "Testing Accuracy: 98.00 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 468/468 [01:12<00:00,  6.27it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 468/468 [00:33<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuary: 99.00 %\n",
      "Testing Accuracy: 98.00 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 468/468 [01:15<00:00,  5.23it/s]\n",
      " 35%|████████████████████████████▍                                                   | 166/468 [00:11<00:20, 14.85it/s]"
     ]
    }
   ],
   "source": [
    "# train and evaluate\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        # TODO:forward + backward + optimize\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = F.nll_loss(output, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "         \n",
    "    # evaluate\n",
    "    # TODO:calculate the accuracy using traning and testing dataset\n",
    "    correct = 0\n",
    "    size = 0\n",
    "    for data, target in tqdm(train_loader):\n",
    "        output = model(data)\n",
    "        predict = output.data.max(1)[1]\n",
    "        size = size + len(predict)\n",
    "        correct = correct + predict.eq(target.data).sum()\n",
    "    print('Training Accuary: %0.2f' %(100.0*correct/size), '%')\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        output = model(data)\n",
    "        predict = output.data.max(1)[1]\n",
    "        correct = correct + predict.eq(target.data).sum()\n",
    "    \n",
    "    print('Testing Accuracy: %0.2f' % (correct/100.0), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5:\n",
    "Please print the training and testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5,padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(16*5*5,120)  # 必须为16*5*5\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "        #self.logsoftmax = nn.LogSoftmax()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        in_size = x.size(0)\n",
    "        out = self.relu(self.mp(self.conv1(x)))\n",
    "        out = self.relu(self.mp(self.conv2(out)))\n",
    "        out = out.view(in_size, -1)\n",
    "        out = self.relu(self.fc1(out))\n",
    "        out = self.relu(self.fc2(out))\n",
    "        out = self.fc3(out)   \n",
    "        return out.log_softmax(out, dim=0)\n",
    "    \n",
    "model = SimpleNet()\n",
    "\n",
    "# TODO:define loss function and optimiter\n",
    "#criterion = F.nll_loss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.015, momentum=0.5)\n",
    "\n",
    "# train and evaluate\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        # TODO:forward + backward + optimize\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = F.nll_loss(output, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "         \n",
    "    # evaluate\n",
    "    # TODO:calculate the accuracy using traning and testing dataset\n",
    "    correct = 0\n",
    "    size = 0\n",
    "    for data, target in tqdm(train_loader):\n",
    "        output = model(data)\n",
    "        predict = output.data.max(1)[1]\n",
    "        size = size + len(predict)\n",
    "        correct = correct + predict.eq(target.data).sum()\n",
    "    print('Training Accuary: %0.2f' %(100.0*correct/size), '%')\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        output = model(data)\n",
    "        predict = output.data.max(1)[1]\n",
    "        correct = correct + predict.eq(target.data).sum()\n",
    "    \n",
    "    print('Testing Accuracy: %0.2f' % (correct/100.0), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
